{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "962365e6-3c28-4db9-a6b4-9ae62fd2201f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import axo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc579d7-84e9-4dae-b8b4-8c3f8df8f49e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations are compartible\n",
      "Generating new config ....\n",
      "File does not exist, creating data file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 07:49:54.744976: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-04 07:49:56.147376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78933 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 9.999999747378752e-06.\n",
      "Epoch 1/480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 07:50:05.277859: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-09-04 07:50:05.410791: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc8641f4a00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-04 07:50:05.410806: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2024-09-04 07:50:05.447788: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-04 07:50:05.586485: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 - 9s - loss: 1.4057 - reco_loss: 0.9582 - kl_loss: 0.4475 - val_loss: 1.3500 - val_reco_loss: 0.9331 - val_kl_loss: 0.4171 - lr: 1.0000e-05 - 9s/epoch - 80ms/step\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 1.9951845388277434e-05.\n",
      "Epoch 2/480\n",
      "110/110 - 1s - loss: 1.2665 - reco_loss: 0.9255 - kl_loss: 0.3410 - val_loss: 1.1885 - val_reco_loss: 0.9121 - val_kl_loss: 0.2766 - lr: 1.9952e-05 - 722ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 2.971177855215501e-05.\n",
      "Epoch 3/480\n",
      "110/110 - 1s - loss: 1.1225 - reco_loss: 0.8751 - kl_loss: 0.2474 - val_loss: 1.0867 - val_reco_loss: 0.8610 - val_kl_loss: 0.2260 - lr: 2.9712e-05 - 722ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 3.913880937034264e-05.\n",
      "Epoch 4/480\n",
      "110/110 - 1s - loss: 0.9861 - reco_loss: 0.8123 - kl_loss: 0.1738 - val_loss: 0.9208 - val_reco_loss: 0.7918 - val_kl_loss: 0.1291 - lr: 3.9139e-05 - 723ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 4.8096993850776926e-05.\n",
      "Epoch 5/480\n",
      "110/110 - 1s - loss: 0.8411 - reco_loss: 0.7434 - kl_loss: 0.0976 - val_loss: 0.7957 - val_reco_loss: 0.7193 - val_kl_loss: 0.0765 - lr: 4.8097e-05 - 718ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 5.64576439501252e-05.\n",
      "Epoch 6/480\n",
      "110/110 - 1s - loss: 0.7454 - reco_loss: 0.6800 - kl_loss: 0.0654 - val_loss: 0.7209 - val_reco_loss: 0.6603 - val_kl_loss: 0.0608 - lr: 5.6458e-05 - 727ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 6.410144123947248e-05.\n",
      "Epoch 7/480\n",
      "110/110 - 1s - loss: 0.6792 - reco_loss: 0.6320 - kl_loss: 0.0471 - val_loss: 0.6580 - val_reco_loss: 0.6192 - val_kl_loss: 0.0390 - lr: 6.4101e-05 - 726ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 7.092043233569711e-05.\n",
      "Epoch 8/480\n",
      "110/110 - 1s - loss: 0.6186 - reco_loss: 0.5861 - kl_loss: 0.0325 - val_loss: 0.5995 - val_reco_loss: 0.5707 - val_kl_loss: 0.0289 - lr: 7.0920e-05 - 736ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 7.681981514906511e-05.\n",
      "Epoch 9/480\n",
      "110/110 - 1s - loss: 0.5710 - reco_loss: 0.5457 - kl_loss: 0.0253 - val_loss: 0.5494 - val_reco_loss: 0.5276 - val_kl_loss: 0.0221 - lr: 7.6820e-05 - 721ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 8.171967783709988e-05.\n",
      "Epoch 10/480\n",
      "110/110 - 1s - loss: 0.5257 - reco_loss: 0.5028 - kl_loss: 0.0230 - val_loss: 0.5131 - val_reco_loss: 0.4885 - val_kl_loss: 0.0248 - lr: 8.1720e-05 - 722ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 7.777853170409799e-05.\n",
      "Epoch 11/480\n",
      "110/110 - 1s - loss: 0.5067 - reco_loss: 0.4775 - kl_loss: 0.0292 - val_loss: 0.5038 - val_reco_loss: 0.4730 - val_kl_loss: 0.0309 - lr: 7.7779e-05 - 728ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 7.356985588558018e-05.\n",
      "Epoch 12/480\n",
      "110/110 - 1s - loss: 0.4929 - reco_loss: 0.4611 - kl_loss: 0.0318 - val_loss: 0.4900 - val_reco_loss: 0.4609 - val_kl_loss: 0.0294 - lr: 7.3570e-05 - 726ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 6.913420656928793e-05.\n",
      "Epoch 13/480\n",
      "110/110 - 1s - loss: 0.4839 - reco_loss: 0.4509 - kl_loss: 0.0330 - val_loss: 0.4837 - val_reco_loss: 0.4507 - val_kl_loss: 0.0331 - lr: 6.9134e-05 - 726ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 6.451426452258602e-05.\n",
      "Epoch 14/480\n",
      "110/110 - 1s - loss: 0.4778 - reco_loss: 0.4429 - kl_loss: 0.0349 - val_loss: 0.4822 - val_reco_loss: 0.4444 - val_kl_loss: 0.0384 - lr: 6.4514e-05 - 724ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 5.975455496809445e-05.\n",
      "Epoch 15/480\n",
      "110/110 - 1s - loss: 0.4745 - reco_loss: 0.4360 - kl_loss: 0.0385 - val_loss: 0.4759 - val_reco_loss: 0.4364 - val_kl_loss: 0.0397 - lr: 5.9755e-05 - 721ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 5.490090188686736e-05.\n",
      "Epoch 16/480\n",
      "110/110 - 1s - loss: 0.4716 - reco_loss: 0.4342 - kl_loss: 0.0374 - val_loss: 0.4725 - val_reco_loss: 0.4342 - val_kl_loss: 0.0387 - lr: 5.4901e-05 - 728ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 5.000004603061825e-05.\n",
      "Epoch 17/480\n",
      "110/110 - 1s - loss: 0.4698 - reco_loss: 0.4316 - kl_loss: 0.0381 - val_loss: 0.4692 - val_reco_loss: 0.4272 - val_kl_loss: 0.0424 - lr: 5.0000e-05 - 727ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 4.509919381234795e-05.\n",
      "Epoch 18/480\n",
      "110/110 - 1s - loss: 0.4675 - reco_loss: 0.4302 - kl_loss: 0.0373 - val_loss: 0.4656 - val_reco_loss: 0.4276 - val_kl_loss: 0.0383 - lr: 4.5099e-05 - 730ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 4.024554436909966e-05.\n",
      "Epoch 19/480\n",
      "110/110 - 1s - loss: 0.4661 - reco_loss: 0.4293 - kl_loss: 0.0368 - val_loss: 0.4660 - val_reco_loss: 0.4242 - val_kl_loss: 0.0420 - lr: 4.0246e-05 - 698ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 3.548583117662929e-05.\n",
      "Epoch 20/480\n",
      "110/110 - 1s - loss: 0.4656 - reco_loss: 0.4282 - kl_loss: 0.0373 - val_loss: 0.4632 - val_reco_loss: 0.4273 - val_kl_loss: 0.0363 - lr: 3.5486e-05 - 693ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 3.0865896405884996e-05.\n",
      "Epoch 21/480\n",
      "110/110 - 1s - loss: 0.4640 - reco_loss: 0.4260 - kl_loss: 0.0380 - val_loss: 0.4639 - val_reco_loss: 0.4238 - val_kl_loss: 0.0404 - lr: 3.0866e-05 - 704ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 2.6430234356666915e-05.\n",
      "Epoch 22/480\n",
      "110/110 - 1s - loss: 0.4637 - reco_loss: 0.4254 - kl_loss: 0.0383 - val_loss: 0.4627 - val_reco_loss: 0.4205 - val_kl_loss: 0.0425 - lr: 2.6430e-05 - 704ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 2.222155853814911e-05.\n",
      "Epoch 23/480\n",
      "110/110 - 1s - loss: 0.4621 - reco_loss: 0.4230 - kl_loss: 0.0391 - val_loss: 0.4615 - val_reco_loss: 0.4219 - val_kl_loss: 0.0398 - lr: 2.2222e-05 - 717ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 1.8280417862115428e-05.\n",
      "Epoch 24/480\n",
      "110/110 - 1s - loss: 0.4618 - reco_loss: 0.4237 - kl_loss: 0.0381 - val_loss: 0.4610 - val_reco_loss: 0.4226 - val_kl_loss: 0.0388 - lr: 1.8280e-05 - 713ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 1.4644746443082113e-05.\n",
      "Epoch 25/480\n",
      "110/110 - 1s - loss: 0.4614 - reco_loss: 0.4230 - kl_loss: 0.0384 - val_loss: 0.4622 - val_reco_loss: 0.4189 - val_kl_loss: 0.0435 - lr: 1.4645e-05 - 705ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 1.134956346504623e-05.\n",
      "Epoch 26/480\n",
      "110/110 - 1s - loss: 0.4615 - reco_loss: 0.4230 - kl_loss: 0.0385 - val_loss: 0.4603 - val_reco_loss: 0.4240 - val_kl_loss: 0.0368 - lr: 1.1350e-05 - 707ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 8.426608474110253e-06.\n",
      "Epoch 27/480\n",
      "110/110 - 1s - loss: 0.4617 - reco_loss: 0.4228 - kl_loss: 0.0390 - val_loss: 0.4595 - val_reco_loss: 0.4206 - val_kl_loss: 0.0391 - lr: 8.4266e-06 - 729ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 5.904026238567894e-06.\n",
      "Epoch 28/480\n",
      "110/110 - 1s - loss: 0.4610 - reco_loss: 0.4228 - kl_loss: 0.0382 - val_loss: 0.4607 - val_reco_loss: 0.4181 - val_kl_loss: 0.0428 - lr: 5.9040e-06 - 715ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 3.8061148188717198e-06.\n",
      "Epoch 29/480\n",
      "110/110 - 1s - loss: 0.4614 - reco_loss: 0.4224 - kl_loss: 0.0389 - val_loss: 0.4602 - val_reco_loss: 0.4178 - val_kl_loss: 0.0426 - lr: 3.8061e-06 - 721ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 2.1530800040636677e-06.\n",
      "Epoch 30/480\n",
      "110/110 - 1s - loss: 0.4618 - reco_loss: 0.4222 - kl_loss: 0.0395 - val_loss: 0.4619 - val_reco_loss: 0.4272 - val_kl_loss: 0.0350 - lr: 2.1531e-06 - 710ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 9.608335176380933e-07.\n",
      "Epoch 31/480\n",
      "110/110 - 1s - loss: 0.4609 - reco_loss: 0.4223 - kl_loss: 0.0386 - val_loss: 0.4600 - val_reco_loss: 0.4183 - val_kl_loss: 0.0418 - lr: 9.6083e-07 - 724ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 2.4086378402898845e-07.\n",
      "Epoch 32/480\n",
      "110/110 - 1s - loss: 0.4608 - reco_loss: 0.4218 - kl_loss: 0.0390 - val_loss: 0.4599 - val_reco_loss: 0.4169 - val_kl_loss: 0.0433 - lr: 2.4086e-07 - 717ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 6.500002928078175e-05.\n",
      "Epoch 33/480\n",
      "110/110 - 1s - loss: 0.4610 - reco_loss: 0.4207 - kl_loss: 0.0403 - val_loss: 0.4652 - val_reco_loss: 0.4207 - val_kl_loss: 0.0449 - lr: 6.5000e-05 - 713ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 6.496088462881744e-05.\n",
      "Epoch 34/480\n",
      "110/110 - 1s - loss: 0.4593 - reco_loss: 0.4180 - kl_loss: 0.0414 - val_loss: 0.4597 - val_reco_loss: 0.4138 - val_kl_loss: 0.0463 - lr: 6.4961e-05 - 722ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 6.484353070845827e-05.\n",
      "Epoch 35/480\n",
      "110/110 - 1s - loss: 0.4591 - reco_loss: 0.4171 - kl_loss: 0.0419 - val_loss: 0.4589 - val_reco_loss: 0.4128 - val_kl_loss: 0.0463 - lr: 6.4844e-05 - 720ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 6.464826583396643e-05.\n",
      "Epoch 36/480\n",
      "110/110 - 1s - loss: 0.4582 - reco_loss: 0.4142 - kl_loss: 0.0439 - val_loss: 0.4585 - val_reco_loss: 0.4132 - val_kl_loss: 0.0458 - lr: 6.4648e-05 - 715ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 6.437555566662923e-05.\n",
      "Epoch 37/480\n",
      "110/110 - 1s - loss: 0.4568 - reco_loss: 0.4139 - kl_loss: 0.0429 - val_loss: 0.4599 - val_reco_loss: 0.4133 - val_kl_loss: 0.0468 - lr: 6.4376e-05 - 735ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 6.402604776667431e-05.\n",
      "Epoch 38/480\n",
      "110/110 - 1s - loss: 0.4556 - reco_loss: 0.4123 - kl_loss: 0.0434 - val_loss: 0.4589 - val_reco_loss: 0.4092 - val_kl_loss: 0.0500 - lr: 6.4026e-05 - 715ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 6.360060069710016e-05.\n",
      "Epoch 39/480\n",
      "110/110 - 1s - loss: 0.4541 - reco_loss: 0.4089 - kl_loss: 0.0452 - val_loss: 0.4520 - val_reco_loss: 0.4112 - val_kl_loss: 0.0409 - lr: 6.3601e-05 - 721ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 6.310021126409993e-05.\n",
      "Epoch 40/480\n",
      "110/110 - 1s - loss: 0.4517 - reco_loss: 0.4051 - kl_loss: 0.0466 - val_loss: 0.4508 - val_reco_loss: 0.4011 - val_kl_loss: 0.0498 - lr: 6.3100e-05 - 723ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 6.252611638046801e-05.\n",
      "Epoch 41/480\n",
      "110/110 - 1s - loss: 0.4499 - reco_loss: 0.4002 - kl_loss: 0.0497 - val_loss: 0.4504 - val_reco_loss: 0.4081 - val_kl_loss: 0.0427 - lr: 6.2526e-05 - 710ms/epoch - 6ms/step\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 6.187968392623588e-05.\n",
      "Epoch 42/480\n",
      "110/110 - 1s - loss: 0.4482 - reco_loss: 0.3996 - kl_loss: 0.0487 - val_loss: 0.4468 - val_reco_loss: 0.3939 - val_kl_loss: 0.0530 - lr: 6.1880e-05 - 734ms/epoch - 7ms/step\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 6.116248550824821e-05.\n",
      "Epoch 43/480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "axo.main() ## This will run in default configuration. To run in custom configuration just added the changes that need to implemented on the base dict and pass to main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8738f43a-a1cb-44d3-9884-73d9e798587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example if we want to train a model with a bigger encoder but with everything else same we run this\n",
    "slave = {\"model\":\n",
    "         {\"encoder_config\":{\"nodes\":[28,64,128]}}\n",
    "        }\n",
    "# If the dictionary is compartible the code will run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4038474-64a9-4182-8add-bf3c56498465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Changing the Learning Rate and Number of Epochs in Training\n",
    "slave = {\n",
    "    \"train\": {\n",
    "        \"common\": {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"n_epochs\": 1000\n",
    "        }\n",
    "    }\n",
    "}\n",
    "axo.main(slave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5adfbc6-ccb6-4fe0-9d42-be751b766fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modifying the File Path and Train/Test Sectors for the Background\n",
    "slave = {\n",
    "    \"data_config\": {\n",
    "        \"Read_configs\": {\n",
    "            \"BACKGROUND\": {\n",
    "                \"file_path\": \"../../new_path/ZB_preprocessed_new.h5\",\n",
    "                \"train_sector\": [0, 3000000],\n",
    "                \"test_sector\": [3000000, 9000000]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "axo.main(slave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4edc91-b57b-40eb-83f7-ba2fd77c6a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Adjusting the Quantization Bits\n",
    "slave = {\n",
    "    \"data_config\": {\n",
    "        \"Quantization_configs\": {\n",
    "            \"quantize_bits\": [10, 6]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "axo.main(slave)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
