# Quantised VAE algorithm configuration.
defaults:
  - _self_

_target_: src.algorithms.vae.VAE
features: null
mask: true
kl_warmup_frac: 0.2

encoder:
  _target_: src.models.encoder.HGQVariationalEncoder
  nodes: [57, 9, 6, 4]
  input_layer_config:
    place: "datalane"
    q_type: "kif"
    i0: 5
    f0: 3
    trainable: false
    ic:
      _target_: hgq.constraints.Constant
      value: 5
    fc:
      _target_: hgq.constraints.Constant
      value: 3
  output_layer_config:
    place: 'all'
    q_type: "kif"
    i0: 5
    f0: 3
    trainable: false
    ic:
      _target_: hgq.constraints.Constant
      value: 5
    fc:
      _target_: hgq.constraints.Constant
      value: 3
  ebops: true

decoder:
  _target_: src.models.decoder.HGQDecoder
  nodes: [4, 6, 9, 57]
  output_layer_config:
    place: 'all'
    q_type: "kif"
    i0: 5
    f0: 3
    trainable: false
    ic:
      _target_: hgq.constraints.Constant
      value: 5
    fc:
      _target_: hgq.constraints.Constant
      value: 3
  ebops: true

loss:
  _target_: src.losses.vae.ClassicVAELoss
  scale: 1
  kl_scale: 0.001

optimizer:
  _partial_: true
  _target_: torch.optim.AdamW
  lr: 0.001
  weight_decay: 0.0
  betas: [0.9, 0.999]
  eps: 1e-8
