_target_: src.data.L1AD_datamodule.L1ADDataModule

# Fill in below with paths to folders that contain the zero bias data.
zerobias: ${paths.zerobias}
signal: ${paths.signal}
background: ${paths.background}

# Folder where the processed data is saved.
processed_data_dir: ${paths.processed_data_dir}/basic

data_extractor:
  _target_: src.data.components.extraction.L1DataExtractor
  objects: [muons, egammas, jets, taus, ET, HT, MET, MHT, FET, FHT, cicada, event_info]
  # Choose what constituents to select from the event by applying a binary mask.
  constituents:
    muons: [True, True, True, True, False, False, False, False]
    egammas: [True, True, True, True, False, False, False, False, False, False, False, False]
    jets: [True, True, True, True, True, True, True, True, True, True, False, False]
    taus: [True, True, True, True, True, True, True, True, True, True, True, True]

data_processor:
  _target_: src.data.components.processing.L1DataProcessor
  processed_data_dir: ${data.processed_data_dir}
  # The features to select are specified by their index in the respective object arrays.
  # The features follow the order in
  # https://github.com/bb511/l1trigger_datamaker/tree/main/l1trigger_datamaker/h5convert
  features:
    muons: [0, 1, 3]
    egammas: [0, 1, 2]
    jets: [0, 1, 2]
    taus: [0, 1, 2]
    ET: [0]
    HT: [0]
    MET: [0, 1]
    MHT: [0, 1]

data_normalizer:
  _target_: src.data.components.normalization.L1DataNormalizer
  norm_scheme: robust
  norm_fit_hyperparams:
    percentiles: [95, 5]
  cache_folder: ${data.processed_data_dir}/${data.data_normalizer.norm_scheme}

# Data hyperparameters.
train_val_test_split: [0.8, 0.1, 0.1]
batch_size: 64
num_workers: 0
pin_memory: False
