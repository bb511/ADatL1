defaults:
  - partitions: axov4

_target_: src.data.L1AD_datamodule.L1ADDataModuleDebug
# _target_: src.data.L1AD_datamodule.L1ADDataModule

# Fill in below with paths to folders that contain the raw data in h5 format.
zerobias: ${paths.zerobias}
signal: ${paths.signal}
background: ${paths.background}

# Extract only the relevant data to use in the processing from the h5 files.
data_extractor:
  _target_: src.data.components.extraction.L1DataExtractor
  # Choose which objects to use and their corresponding features.
  objects_features:
    muons: ['muonIEt', 'muonIEta', 'muonIPhi']
    egammas: ['egIEt', 'egIEta', 'egIPhi']
    jets: ['jetIEt', 'jetIEta', 'jetIPhi']
    ET: ['Et']
    MET: ['Et', 'phi']
  # For the particle objects, choose which constituents to use.
  constituents:
    muons: [True, True, True, True, False, False, False, False]
    egammas: [True, True, True, True, False, False, False, False, False, False, False, False]
    jets: [True, True, True, True, True, True, True, True, True, True, False, False]
  cache: ${paths.data_dir}/extracted
  name: axol1tl

# Processing of the data.
# Events saturated in the pT/transverse energy are masked/removed.
# Specify which objects/features to remove from the data.
data_processor:
  _target_: src.data.components.processing.L1DataProcessor
  extracted_path: ${data.data_extractor.cache}/${data.data_extractor.name}
  remove_objects_features:
    ET: ['Et']
  cache: ${paths.data_dir}/processed
  name: axol1tl

# Normalize the data.
# Choose which type of normalization to use and give hyperparameters of that
# normalization scheme, if any.
data_normalizer:
  _target_: src.data.components.normalization.L1DataNormalizer
  norm_scheme: changrobust
  norm_hyperparams:
    percentiles: [95, 5]
    scale: [2, -2]
  ignore_zeros: True
  output_dtype: float32
  cache: ${paths.data_dir}/normed/${data.data_processor.name}
  processed_data_folder: ${data.data_processor.cache}/${data.data_processor.name}

# Split the main data set into 80% training, 10% validation, 10% test.
split: [0.8, 0.1, 0.1]

# Parameters specifying how and where the data is loaded.
batch_size: 16384
val_batches: 1
