_target_: src.models.qvae.QVAE

features: null 

encoder:
  _target_: src.models.components.qvae.QuantizedEncoder

  # 57 input features, 8 latent features
  nodes: [57, 28, 15, 8] 

  qdata:
    _target_: src.models.quantization.quantizers.FixedPointQuantizer
    bits: 8
    integer: 5

  qweight:
    _target_: src.models.quantization.quantizers.FixedPointQuantizer
    bits: 6
    integer: 2

  qbias:
    _target_: src.models.quantization.quantizers.FixedPointQuantizer
    bits: 10
    integer: 6

  qactivation:
    _target_: src.models.quantization.quantizers.FixedPointQuantizer
    bits: 10
    integer: 6
  
decoder:
  _target_: src.models.components.qvae.Decoder

  nodes: [8, 15, 28, 57] # inverse of the encoder nodes

  # ------------------------------------------------------------------------------------
  # Fancy way of defining the nodes: interpolate from the encoder nodes
  # nodes:
  #   - '${list_at_idx: ${model.encoder.nodes}, -1}'
  #   - 16
  #   - 32
  #   - 64
  #   - 128
  #   - '${list_at_idx: ${model.encoder.nodes}, 0}'
  # ------------------------------------------------------------------------------------

  init_last_weight:
    _target_: src.utils.hydra.get_method
    path: torch.nn.init.uniform_
    a: -0.05
    b: 0.05

  init_last_bias: null

loss:
  _target_: src.models.losses.vae.VAELoss
  beta: 0.604108559135001
  reduction: none

optimizer:
  _partial_: true
  _target_: src.models.optimizers.lion.Lion
  lr: 0.0001
  # betas: (0.9, 0.99)
  weight_decay: 0.0

scheduler:
  # here other attributes...
  scheduler:
    _partial_: true
    _target_: src.models.optimizers.cdrw.CDRW
    lr0: ${model.optimizer.lr} 
    s0: 32
    t_mul: 2.0
    m_mul: 0.65
    alpha: 1e-6
    warmup_epochs: 10
    last_epoch: -1
